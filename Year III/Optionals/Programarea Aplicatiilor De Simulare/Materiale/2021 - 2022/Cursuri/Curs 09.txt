Flow:
============

Sense -> Decide -> Act

Show nav mesh bounds volume
Show Recast nav mesh properties of generation versus radius of the agent and height of the agent by raising the cubes
Show the NavModifierVolume
Support for different navmeshes, Check Engine - Navigation System in project settings

Show and explain the AI_ThirdPersonCharacter and functionality

Start Gameplay debugger (`) and see AI in character in Spectator (Tab key)


============================

Sensing : https://learn.unrealengine.com/course/3318392/module/6636119/Scorm?LPId=0&Review=False&Reattempt=True

The AI Perception Stimuli Source component will determine which 'perceptible' properties an Actor has, whereas the 


The AI Perception Component - determines which senses can be used, or sensed. allows us to configure which senses the perception system can use or "see." Multiple senses can be added in a single component. Additionally, you can use the Dominant Sense property to specify one sense having precedence over other senses when determining a sensed Actors location. For example, in video games you may want to prioritize the "seeing" sense over "hearing" sense.  


AI PERCEPTION STIMULI SOURCE - Adding this component to an actor will determine which senses the AI Perception system will register. For example, if you set your AI Perception Stimuli Source as a stimuli for sight then AI which are configured to perceive sight will sense the Actor. A single component can be registered with multiple stimuli.

====================

-> Show the AI_ThirdPersonCharacter and AIPerception component configured with the sensing
-> Show the ThirdPersonCharacter and AIPerceptionStimuli Source with the properties of AIPerception. 

-> Show in Spectator and gameplay debugger by activating perception (NumPad 5) the sight stimuli, present the distance and age meaning.

-> Show the OnTargetPerceptionUpdated on tthe AI_ThirdPersonCharacter EventGraph functionality and stimulus checking

===================
Behavior tree theory: https://learn.unrealengine.com/course/3318392/module/6661280/Scorm?LPId=0


-> Show the BT_ and BB_ assets and how they related to the AI Controller
-> Show a task implemenation, FindNavigableLocation and how it sets a key

-> Check the UpdateTargetACtors and UpdateHaslineOfSight functions in the AIC_ThirdPersonCharacter, and how these updates things on the blackboard

-> Check and explain the full behavior tree on AIC_ThirdPersonCharacter,  
-decorators
-Wait nodes
-priorities, abort

-> Show in-editor debugging of the behavior tree with step forward/back and blackboard variables, values, breakpoints.
-> Show in Gameplay debugger output from behavior trees

-> Explain EQS_FindClosestFood and EQS_FindClosestPlayer

-> Explain the BTS_Hunger service and how it is added to the BT_EnemyAI.
-> Explain the decorator condition before running FindFood and the KeyQuery in the property and value that will execute the children when hunger is maximum (1.0)
-> Explain in debugger how the selector node priorities run when the AI sees the player even if hungry; Check how hungry parameter grows over time and reacts accordingly


-> Testing and debugging EQS: Show the EQS_Pawn_Test, put in the world and select from the properties EQS, one of the two queries that we have. Show what capabilities we have.
   Also show GameplayDebugger and stuff in details


